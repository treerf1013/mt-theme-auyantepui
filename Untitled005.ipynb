{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOatB2/GQO3onUvobJkApZu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treerf1013/mt-theme-auyantepui/blob/master/Untitled005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PskElcivtSW0",
        "outputId": "602e18d4-f964-4afe-d802-2f637b72d0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-l_81ikhw\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-l_81ikhw\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 15.9 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=b3b4d8d550447d2906c8d43cd5aed987afd7590ac2af8eafad03e6b49c900083\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dkn3udcc/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1 whisper-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVYQ3RFltUY8",
        "outputId": "1a85b505-abb3-48a3-f407-b073603dab25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:09<00:00, 50.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"/content/sample_data/youtube005.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE6awhgBtZLR",
        "outputId": "99c633e5-3220-44e7-a2cf-8e9b46c5ddd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Il n'y a plus de champagne sur les podiums de Formula, mais non, c'est du vin... Il n'y a plus de champagne? Mais non. C'est un pétion italien. C'est un pétion italien. Qui permet à Ferrari d'être toujours sur les podiums puisqu'il se nomme de la sorte. Donc Ferrari est toujours sur les podiums. Ah oui, donc ça ne nous appartient pas. Donc c'est commercial, c'est pas pour bannir le champagne? Commercial, enfin, ça m'étonne ça. Vous regrettez qu'il y a plus de champagne, vous vous en buviez autant que vous vous douchez avec? Non, on ne buvait pas, mais je trouvais que c'était quand même une tradition géniale. C'est vrai. Et moi, j'avais une sorte de petit pari au départ pour pouvoir faire le vin, regarder les podiums, quand je squai la manière de mettre le pouce, mais c'était une chance un peu au départ, il vous verrait qu'il y avait toujours un vin comme ça. Jusqu'en les moindres détailles, le vin de la victoire dans les bulles de champagne. La technique des voitures, la technique du V et puis un sacré entraînement physique. Ça c'est l'entraînement aujourd'hui pour les pilotes? Ça c'est l'entraînement, c'est vrai que c'est un sport honnêtement du point de vue extérieur, c'est difficile de se rendre compte parce que je fais toujours le parallèle avec d'autres sports comme le foot ou le tennis où tous les gens peuvent aller sur un cours et essayer de jouer comme Nadal ou Fédéraire et se rendre compte de l'effort physique que ça demande. Pareil en foot, tout le monde peut aller courir et jouer au foot sur un terrain pendant 90 minutes, mais nous malheureusement, personne peut ressentir les forces, la concentration que ça demande, la chaleur qu'il fait dans les voitures parce qu'on peut entre 2 à 3 kilos pendant un grand prix et tout ça en roulant à 350, on ne peut pas perdre la lucidité pendant tout ce temps. Donc ça demande une vraie condition physique et on se rend un peu plus compte avec les exercices qu'on fait, mais c'est vraiment intense. Parce qu'on voit le travail du coup, évidemment, qui prend vachement même si tout est bien équipé. Le coup, le dos, oui. Les bras, évidemment. On voit le travail sur les volants parce que à 350 le volant faut le... Il faut le tenir, oui. C'est vrai que il y a plusieurs exercices. En fait, il y a un exercice physique, il y a un exercice mental. Il y a des circuits qui sont vraiment très compliqués physiquement et d'autres, comme Monaco, quand on roule à 300 km dans les rues de Monaco, en passant à quelques centimètres des murs pendant 2 heures, il y a une fatigue qui s'installe en termes de mental et psychologique parce que ça devient presque un challenge avec soi-même, justement, de rester dans ce niveau d'attention extrêmement. Vous avez aussi ce genre de préparation? Moins, quand même. En fin de compte, par rapport à notre période, c'est le reflet, la différence. C'est-à-dire qu'eux, ils font 23 courses et ils font du simulateur. Ils ne font pas d'essais. Alors que nous, on faisait en moyenne 3-4 jours d'essais par semaine. Donc, on faisait de l'entraînement physique, mais pas aussi poussé avec les machines, même si les machines, moi je me rappelle avec Ronne Poulain, qu'on avait fait de... Mais le matin, il y a des machines à été incroyables. Par exemple, on avait fait des essais de cette machine sur les muscles. Et en fin de compte, moi je me suis aperçu que c'était pas bon pour moi. Parce que, comme on roulait beaucoup, on avait une musculature naturelle dans la voiture. Et on avait énormément avec les... on en reparlera, les voitures ajoutent à l'époque, tout ça, qui donnaient beaucoup de... Donc, cette musculature, on la faisait naturellement. Eux, ils sont migés de la faire un peu dans les salles avec la gym, etc. Tout évolue. – Toujours au rayon entraînement, Pierre, on voulait montrer ces images qui ont fait le tour des réseaux sociaux. Je crois qu'on va les voir là, si ça... Alors, je peux vous dire qu'on s'est entraînés tout l'après-midi au bureau. Et c'est là qu'on voit que le réflexe n'est pas inné, mais le réflexe est vital dans votre métier. – Ouais, c'est vrai que c'est... C'est genre d'exercice qu'on fait. Souvent, on a besoin, comme je l'ai dit, à la vitesse à laquelle on voit. On a besoin d'être extrêmement réactifs et...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3NE3kMItjYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}